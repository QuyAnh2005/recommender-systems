{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f316929",
   "metadata": {},
   "source": [
    "# User-Based Approach\n",
    "\n",
    "## Overview\n",
    "- [1. Notation](#1)\n",
    "- [2. Book ratings dataset](#2)\n",
    "- [3. Collaborative filtering learning algorithm](#3)\n",
    "- [4. Learn recommendations](#4)\n",
    "- [5. References](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cfefba",
   "metadata": {},
   "source": [
    "##  Packages <img align=\"left\" src=\"./images/film_strip_vertical.png\"     style=\" width:40px;   \" >\n",
    "We will use the now familiar NumPy and Tensorflow Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05947dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244b4e8",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Notation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bf7b8",
   "metadata": {},
   "source": [
    "|General <br />  Notation  | Description| Python (if any) |\n",
    "|:-------------|:------------------------------------------------------------||\n",
    "| $r(i,j)$     | scalar; = 1  if user j rated book i  = 0  otherwise             ||\n",
    "| $y(i,j)$     | scalar; = rating given by user j on book  i    (if r(i,j) = 1 is defined) ||\n",
    "|$\\mathbf{w}^{(j)}$ | vector; parameters for user j ||\n",
    "|$b^{(j)}$     |  scalar; parameter for user j ||\n",
    "| $\\mathbf{x}^{(i)}$ |   vector; feature ratings for movie i        ||     \n",
    "| $n_u$        | number of users |num_users|\n",
    "| $n_m$        | number of books | num_books |\n",
    "| $n$          | number of features | num_features                    |\n",
    "| $\\mathbf{X}$ |  matrix of vectors $\\mathbf{x}^{(i)}$         | X |\n",
    "| $\\mathbf{W}$ |  matrix of vectors $\\mathbf{w}^{(j)}$         | W |\n",
    "| $\\mathbf{b}$ |  vector of bias parameters $b^{(j)}$ | b |\n",
    "| $\\mathbf{R}$ | matrix of elements $r(i,j)$                    | R |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f2454",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2. Book ratings dataset <img align=\"left\" src=\"./images/film_rating.png\"     style=\" width:40px;  \" >\n",
    "\n",
    "The original dataset has more 1 milions books rated by more 3 milions users. The dataset has been reduced in size to focus on first 1000 rows. This dataset consists of ratings on a scale of 0 to 10 in 1 step increments. The reduced dataset has $n_u = 986$ users, and $n_m= 164$ books. \n",
    "\n",
    "Below, you will load the movie dataset into the variables $Y$ and $R$.\n",
    "\n",
    "The matrix $Y$ (a  $n_m \\times n_u$ matrix) stores the ratings $y^{(i,j)}$. The matrix $R$ is an binary-valued indicator matrix, where $R(i,j) = 1$ if user $j$ gave a rating to book $i$, and $R(i,j)=0$ otherwise. \n",
    "\n",
    "Throughout this part of the exercise, you will also be working with the\n",
    "matrices, $\\mathbf{X}$, $\\mathbf{W}$ and $\\mathbf{b}$: \n",
    "\n",
    "$$\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{x}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{x}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{x}^{(n_m-1)})^T --- \\\\\n",
    "\\end{bmatrix} , \\quad\n",
    "\\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{w}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{w}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{w}^{(n_u-1)})^T --- \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{ b} = \n",
    "\\begin{bmatrix}\n",
    " b^{(0)}  \\\\\n",
    " b^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "b^{(n_u-1)} \\\\\n",
    "\\end{bmatrix}\\quad\n",
    "$$ \n",
    "\n",
    "The $i$-th row of $\\mathbf{X}$ corresponds to the\n",
    "feature vector $x^{(i)}$ for the $i$-th movie, and the $j$-th row of\n",
    "$\\mathbf{W}$ corresponds to one parameter vector $\\mathbf{w}^{(j)}$, for the\n",
    "$j$-th user. Both $x^{(i)}$ and $\\mathbf{w}^{(j)}$ are $n$-dimensional\n",
    "vectors. For the purposes of this exercise, you will use $n=10$, and\n",
    "therefore, $\\mathbf{x}^{(i)}$ and $\\mathbf{w}^{(j)}$ have 10 elements.\n",
    "Correspondingly, $\\mathbf{X}$ is a\n",
    "$n_m \\times 10$ matrix and $\\mathbf{W}$ is a $n_u \\times 10$ matrix.\n",
    "\n",
    "We will start by loading the movie ratings dataset to understand the structure of the data.\n",
    "We will load $Y$ and $R$ with the movie dataset.  \n",
    "We'll also load $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$ with pre-computed values. These values will be learned later in the lab, but we'll use pre-computed values to develop the cost model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e27814",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Collaborative filtering learning algorithm <img align=\"left\" src=\"./images/film_filter.png\"     style=\" width:40px;  \" >\n",
    "\n",
    "Now, you will begin implementing the collaborative filtering learning\n",
    "algorithm. You will start by implementing the objective function. \n",
    "\n",
    "The collaborative filtering algorithm in the setting of movie\n",
    "recommendations considers a set of $n$-dimensional parameter vectors\n",
    "$\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)}$, $\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$ and $b^{(0)},...,b^{(n_u-1)}$, where the\n",
    "model predicts the rating for movie $i$ by user $j$ as\n",
    "$y^{(i,j)} = \\mathbf{w}^{(j)}\\cdot \\mathbf{x}^{(i)} + b^{(j)}$ . Given a dataset that consists of\n",
    "a set of ratings produced by some users on some movies, you wish to\n",
    "learn the parameter vectors $\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\n",
    "\\mathbf{w}^{(0)},...,\\mathbf{w}^{(n_u-1)}$  and $b^{(0)},...,b^{(n_u-1)}$ that produce the best fit (minimizes\n",
    "the squared error). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71fed1",
   "metadata": {},
   "source": [
    "\n",
    "### Collaborative filtering cost function\n",
    "\n",
    "The collaborative filtering cost function is given by\n",
    "$$J({\\mathbf{x}^{(0)},...,\\mathbf{x}^{(n_m-1)},\\mathbf{w}^{(0)},b^{(0)},...,\\mathbf{w}^{(n_u-1)},b^{(n_u-1)}})= \\left[ \\frac{1}{2}\\sum_{(i,j):r(i,j)=1}(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+ \\underbrace{\\left[\n",
    "\\frac{\\lambda}{2}\n",
    "\\sum_{j=0}^{n_u-1}\\sum_{k=0}^{n-1}(\\mathbf{w}^{(j)}_k)^2\n",
    "+ \\frac{\\lambda}{2}\\sum_{i=0}^{n_m-1}\\sum_{k=0}^{n-1}(\\mathbf{x}_k^{(i)})^2\n",
    "\\right]}_{regularization}\n",
    "\\tag{1}$$\n",
    "The first summation in (1) is \"for all $i$, $j$ where $r(i,j)$ equals $1$\" and could be written:\n",
    "\n",
    "$$\n",
    "= \\left[ \\frac{1}{2}\\sum_{j=0}^{n_u-1} \\sum_{i=0}^{n_m-1}r(i,j)*(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)} - y^{(i,j)})^2 \\right]\n",
    "+\\text{regularization}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9193f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the collaborative filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (num_books,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_books,num_users)    : matrix of user ratings of books\n",
    "      R (ndarray (num_books,num_users)    : matrix, where R(i, j) = 1 if the i-th books was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "      \n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    \n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c161a3",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4. Learn recommendations\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fb96901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload ratings\n",
    "PATH = \"./preprocessed\"\n",
    "\n",
    "# Load R matrix from file\n",
    "R = np.load(f'{PATH}/R.npy', allow_pickle=True)\n",
    "# Load Y matrix from file\n",
    "Y = np.load(f'{PATH}/Y.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f10c75cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(Y, R):\n",
    "    \"\"\"\n",
    "    Preprocess data by subtracting mean rating for every book (every row).\n",
    "    Only include real ratings R(i,j)=1.\n",
    "    \n",
    "    [Y_norm, Y_mean] = normalize(Y, R) normalized Y so that each book\n",
    "    has a rating of 0 on average. Unrated moves then have a mean rating (0)\n",
    "    \n",
    "    Returns the mean rating in Y_mean.\n",
    "    \"\"\"\n",
    "    Y_mean = (np.sum(Y * R, axis=1) / (np.sum(R, axis=1) + 1e-12)).reshape(-1, 1)\n",
    "    Y_norm = Y - np.multiply(Y_mean, R)\n",
    "    \n",
    "    return(Y_norm, Y_mean)\n",
    "\n",
    "# Normalize the Dataset\n",
    "Y_norm, Y_mean = normalize(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c057e3",
   "metadata": {},
   "source": [
    "<a name=\"4.2\"></a>\n",
    "### 4.2 Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "770c29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_books, num_users = Y.shape\n",
    "num_features = 10\n",
    "lr = 1e-1\n",
    "lambda_ = 1\n",
    "iterations = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a93a3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 8591.7\n",
      "Training loss at iteration 20: 457.2\n",
      "Training loss at iteration 40: 77.7\n",
      "Training loss at iteration 60: 13.2\n",
      "Training loss at iteration 80: 2.9\n",
      "Training loss at iteration 100: 1.1\n",
      "Training loss at iteration 120: 0.8\n",
      "Training loss at iteration 140: 0.7\n",
      "Training loss at iteration 160: 0.7\n",
      "Training loss at iteration 180: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "\n",
    "W = tf.Variable(tf.random.normal((num_users, num_features), dtype=tf.float64), name='W')\n",
    "X = tf.Variable(tf.random.normal((num_books, num_features), dtype=tf.float64), name='X')\n",
    "b = tf.Variable(tf.random.normal((1, num_users), dtype=tf.float64), name='b')\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=lr)\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cost_function(X, W, b, Y_norm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient(cost_value, [X, W, b])\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f9889f",
   "metadata": {},
   "source": [
    "## References\n",
    "- [Unsupervised Learning, Recommenders, Reinforcement Learning](https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning?specialization=machine-learning-introduction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
